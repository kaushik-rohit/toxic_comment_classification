# toxic_comment_classification

Abuse isn't just physical. The online abuse in terms of toxic comments on social media or wikipedia's talk page are becoming more and more regular. With the developments in machine learning and natural language processing, it is possible to identify such hate comments and, thus, also identify the abuser for criminal justice. In this paper, we present three learning models, namely, a simple  linear baseline based on logistic regression, a bidirectional gated recurrent unit based convolutional network with GloVe embeddings, and a BERT model. We report the standard F1 scores and AUC scores for the models and compare our scores to one of the best research done in this topic and report relative increase of 4% accuracy. We were able to achieve accuracy as high as 98% with the BERT model but with a trade-off. Our CNN-BiGRU model achieves accuracy of 97%. Overall, our models improve upon the previous results and we find the CNN-BiGRU model to be the best one.
